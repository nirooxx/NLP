# README â€“ Sentiment-Analyse von Tweets

## ProjektÃ¼bersicht
Dieses Projekt fÃ¼hrt eine Sentiment-Analyse von Tweets durch und klassifiziert diese als positiv oder negativ.

Es kombiniert verschiedene moderne NLP-Techniken wie:

- **TF-IDF**: Text-Vektorisierung auf Basis von Wort- und Bi-Gram-HÃ¤ufigkeiten.
- **GloVe**: Vortrainierte Wort-Embeddings zur semantischen ReprÃ¤sentation von WÃ¶rtern.
- **Emoji2Vec**: Spezialisierte Vektoren fÃ¼r Emojis.
- **BERT**: Kontextuelle Embeddings fÃ¼r tiefere semantische Analysen.
- **LightGBM**: Ein leistungsstarker Algorithmus zur Klassifikation der Daten.

## Projektstruktur
Das Projekt ist wie folgt organisiert:

```plaintext
nlp-assignment/
â”œâ”€â”€ ðŸ“‚ data/                       # EnthÃ¤lt Embeddings oder Daten
â”‚   â”œâ”€â”€ glove.twitter.27B.200d.txt # GloVe-Embeddings (nicht enthalten)
â”‚   â”œâ”€â”€ emoji2vec.txt              # Emoji2Vec-Embeddings (nicht enthalten)
â”œâ”€â”€ notebooks/                     # Optional: Jupyter-Notebook fÃ¼r Analysen
â”‚   â”œâ”€â”€ nlp_assignment.ipynb       # EnthÃ¤lt erklÃ¤rende Zellen und Code
â”œâ”€â”€ ðŸ“‚ src/                        # EnthÃ¤lt alle Python-Skripte
â”‚   â”œâ”€â”€ dataset_preparation.py     # Funktionen zum Laden und Aufteilen der Daten
â”‚   â”œâ”€â”€ download_data.py           # LÃ¤dt notwendige NLTK-Daten
â”‚   â”œâ”€â”€ main.py                    # Hauptskript zur AusfÃ¼hrung der Pipeline
â”‚   â”œâ”€â”€ preprocess.py              # Funktionen fÃ¼r Textbereinigung und Feature-Engineering
â”‚   â”œâ”€â”€ train_model.py             # Training, Bewertung und Visualisierung des Modells
â”œâ”€â”€ requirements.txt               # Liste der Python-Bibliotheken
â”œâ”€â”€ README.md                      # Projektbeschreibung und Anleitung
```
## Voraussetzungen
FÃ¼r die AusfÃ¼hrung des Projekts werden folgende Voraussetzungen benÃ¶tigt:

- **Python-Version**: 3.8 oder hÃ¶her
- **Internetverbindung**: Zum Herunterladen von NLTK-Daten, falls sie nicht vorhanden sind
- **Speicherplatz**: FÃ¼r groÃŸe Embeddings wie GloVe (ca. 1 GB) und Emoji2Vec

## Schritt-fÃ¼r-Schritt-Anleitung

### 1. Installiere die AbhÃ¤ngigkeiten
Navigiere in das Projektverzeichnis:
```bash
cd nlp-assignment
```
Installiere die benÃ¶tigten Python-Bibliotheken:

```bash
pip install -r requirements.txt
```

### Wichtige Python-Bibliotheken
- **nltk**: FÃ¼r Textverarbeitung.
- **numpy**: Verarbeitung von numerischen Daten.
- **scikit-learn**: Datenaufteilung, Metriken.
- **transformers**: BERT-Modelle und Tokenizer.
- **lightgbm**: Training des Modells.

### 2. Stelle sicher, dass die notwendigen Daten verfÃ¼gbar sind
Das Projekt benÃ¶tigt die folgenden vortrainierten Embeddings, die **nicht in der Abgabe enthalten** sind:

- **GloVe**:  
  Lade die Datei `glove.twitter.27B.200d.txt` von der offiziellen Seite herunter:  
  [GloVe Embeddings](https://nlp.stanford.edu/projects/glove/)  
  Verschiebe die Datei in den Ordner `data/`.

- **Emoji2Vec**:  
  Lade die Datei `emoji2vec.txt` von GitHub herunter:  
  [Emoji2Vec](https://github.com/uclnlp/emoji2vec)  
  Verschiebe die Datei ebenfalls in den Ordner `data/`.

### 3. FÃ¼hre das Projekt aus
Das gesamte Projekt kann durch AusfÃ¼hren der `main.py` gestartet werden:
```bash
python src/main.py
```
WÃ¤hrend der AusfÃ¼hrung:

- LÃ¤dt das Skript automatisch die notwendigen NLTK-Daten herunter (falls sie nicht vorhanden sind).
- Vektorisiert die Tweets mit TF-IDF, GloVe, Emoji2Vec und BERT.
- Trainiert ein LightGBM-Modell und bewertet dessen Leistung.

### 4. Ergebnisse
Nach der erfolgreichen AusfÃ¼hrung des Projekts sehen Sie:

1. **Testgenauigkeit** des Modells:  
   - Die Gesamtgenauigkeit, beispielsweise `96.40%`.

2. **Classification Report**:  
   - Ein detaillierter Bericht mit folgenden Metriken:  
     - **Precision**: Anteil korrekter positiver Vorhersagen.  
     - **Recall**: Anteil korrekter Vorhersagen unter allen tatsÃ¤chlichen positiven Instanzen.  
     - **F1-Score**: Harmonisches Mittel aus Precision und Recall.

3. **Confusion Matrix**:  
   - Eine grafische Darstellung der True Positives, True Negatives, False Positives und False Negatives.  

Diese Ergebnisse bieten Einblicke in die LeistungsfÃ¤higkeit des Modells und helfen, potenzielle Verbesserungsbereiche zu identifizieren.

## Datenquellen

- **NLTK Twitter-Datensatz**:  
  - Positiv und negativ klassifizierte Tweets.  
  - Wird automatisch beim ersten AusfÃ¼hren heruntergeladen.

- **GloVe Embeddings**:  
  - Zur semantischen ReprÃ¤sentation von WÃ¶rtern.  
  - Download-Link: [GloVe](https://nlp.stanford.edu/projects/glove/)

- **Emoji2Vec Embeddings**:  
  - Zur Verarbeitung von Emojis.  
  - Download-Link: [Emoji2Vec](https://github.com/uclnlp/emoji2vec)

## ProblemlÃ¶sung

Falls Fehler auftreten:

- **AbhÃ¤ngigkeiten nicht installiert**:  
  Stelle sicher, dass Sie folgenden Befehl ausgefÃ¼hrt haben:  
```bash
  pip install -r requirements.txt
```

- **Fehlende Daten**:
ÃœberprÃ¼fe, ob die Dateien `glove.twitter.27B.200d.txt` und `emoji2vec.txt` im Ordner `data/` vorhanden sind.

- **Speicherprobleme**:
Falls GloVe und BERT zu viel Speicher beanspruchen, kÃ¶nnen Sie kleinere Embeddings verwenden oder das Projekt mit nur TF-IDF und Emoji2Vec ausfÃ¼hren.

## ErweiterungsmÃ¶glichkeiten
- **Hyperparameter-Tuning**: Verbesserung der Genauigkeit durch Optimierung von LightGBM.
- **Datenaugmentation**: ErhÃ¶hen der Trainingsdaten durch Synonymersetzung oder Ãœbersetzungen.
- **Andere Embeddings**: Testen von Alternativen wie FastText oder RoBERTa.






