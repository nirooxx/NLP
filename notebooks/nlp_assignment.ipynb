{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Tweet Sentiment Analysis ‚Äì Logistische Regression\n",
    "\n",
    "## **Projektziel**\n",
    "Dieses Projekt befasst sich mit der **Klassifikation von Tweets** in positive und negative Kategorien.  \n",
    "Dazu nutzen wir **Natural Language Processing (NLP)** und eine **logistische Regression**, um den Sentiment-Wert eines Tweets vorherzusagen.\n",
    "\n",
    "Das Projekt folgt den **vier Aufgabenstellungen** der Pr√ºfungsleistung:\n",
    "\n",
    "1. **Datenaufbereitung (Aufgabe 1)**:\n",
    "   - Laden des **NLTK Twitter-Datensatzes** mit positiven und negativen Tweets.\n",
    "   - Erstellung von **Trainings-, Validierungs- und Testdatens√§tzen**.\n",
    "\n",
    "2. **Feature Engineering & Preprocessing (Aufgabe 2)**:\n",
    "   - Bereinigung der Tweets (z. B. **Entfernung von URLs, Mentions, Sonderzeichen**).\n",
    "   - Tokenisierung, Stopword-Entfernung und **Stemming/Lemmatization**.\n",
    "   - Umwandlung in numerische Repr√§sentationen mit **TF-IDF**.\n",
    "\n",
    "3. **Modelltraining & Evaluation (Aufgabe 3)**:\n",
    "   - Training einer **logistischen Regression** mit Scikit-learn.\n",
    "   - **Bewertung der Modellleistung** anhand von **Genauigkeit (Accuracy), F1-Score und Confusion-Matrix**.\n",
    "\n",
    "4. **Wissenschaftliche Analyse (Aufgabe 4, separate PDF)**:\n",
    "   - **Beschreibung des aktuellen Stands von NLP** mit Referenzen zum **State of AI Report** und **AI Index**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Methodik**\n",
    "Dieses Projekt nutzt **moderne NLP-Techniken**, um Textdaten in eine mathematische Form zu √ºberf√ºhren:\n",
    "\n",
    "- **TF-IDF** (Term Frequency-Inverse Document Frequency):  \n",
    "  Eine Technik, um wichtige W√∂rter zu identifizieren, indem sie in Relation zur gesamten Textmenge gewichtet werden.\n",
    "\n",
    "- **Tokenisierung & Stemming**:  \n",
    "  Zerlegt S√§tze in einzelne W√∂rter und reduziert sie auf ihre Grundformen (z. B. *\"running\"* ‚Üí *\"run\"*).\n",
    "\n",
    "- **Logistische Regression**:  \n",
    "  Ein Algorithmus zur Klassifikation, der zwischen positiven und negativen Tweets unterscheidet.\n",
    "\n",
    "---\n",
    "\n",
    "## **Datenquelle**\n",
    "Die Daten stammen aus dem **NLTK Twitter-Datensatz**, bestehend aus:\n",
    "- **Positive Tweets**: Gl√ºckliche oder optimistische Inhalte.\n",
    "- **Negative Tweets**: Kritische oder w√ºtende Inhalte.\n",
    "\n",
    "Die Daten werden in **80 % Training, 10 % Validierung und 10 % Testdaten** aufgeteilt.\n",
    "\n",
    "---\n",
    "\n",
    "## **Zielsetzung**\n",
    "- **Erreichen einer Modellgenauigkeit von mindestens 90 % auf den Testdaten**.\n",
    "- **Interpretierbare Ergebnisse durch eine Konfusionsmatrix und F1-Score**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 1: Laden des NLTK Twitter-Datensatzes\n",
    "In diesem Abschnitt:\n",
    "- Laden wir den **Standard-Twitter-Datensatz** von NLTK.\n",
    "- Teilen die Daten in **positive und negative Tweets** auf.\n",
    "- Zeigen einige Beispiel-Tweets zur Veranschaulichung.\n",
    "\n",
    "Die aufbereiteten Daten werden sp√§ter in **Trainings-, Validierungs- und Testsets** unterteilt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Korrigiere den Modulpfad, um zum `src`-Verzeichnis zu gelangen\n",
    "module_path = os.path.abspath(os.path.join(\"..\", \"src\"))  # Gehe ein Verzeichnis zur√ºck und dann in \"src\"\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "\n",
    "# Import der notwendigen Funktion zur Datenvorbereitung\n",
    "from dataset_preparation import load_twitter_data\n",
    "\n",
    "# Positive und negative Tweets laden\n",
    "positive_tweets, negative_tweets = load_twitter_data()\n",
    "\n",
    "# Ausgabe der Anzahl positiver und negativer Tweets\n",
    "print(f\"Anzahl positiver Tweets: {len(positive_tweets)}\")\n",
    "print(f\"Anzahl negativer Tweets: {len(negative_tweets)}\")\n",
    "\n",
    "# Beispiele anzeigen\n",
    "print(\"\\nBeispiel positiver Tweet:\")\n",
    "print(positive_tweets[0])\n",
    "print(\"\\nBeispiel negativer Tweet:\")\n",
    "print(negative_tweets[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Importe und Ressourcen\n",
    "\n",
    "In diesem Schritt werden alle ben√∂tigten Bibliotheken und Ressourcen importiert.  \n",
    "Zus√§tzlich laden wir vortrainierte Modelle, um sie sp√§ter f√ºr das **Feature Engineering** zu verwenden.\n",
    "\n",
    "---\n",
    "\n",
    "## **Verwendete Bibliotheken**\n",
    "- **NLTK**: F√ºr Textverarbeitung wie Tokenisierung und Stoppwortentfernung.\n",
    "- **Scikit-Learn**: Modelltraining, TF-IDF-Vektorisierung & Standardisierung.\n",
    "- **Transformers (Hugging Face)**: F√ºr das Laden des BERT-Modells.\n",
    "- **LightGBM**: Leistungsf√§higer Algorithmus f√ºr das Modelltraining.\n",
    "- **Eigene Module**: Importieren unserer vorbereiteten Funktionen f√ºr Datenverarbeitung & Modelltraining.\n",
    "\n",
    "---\n",
    "\n",
    "## **Vortrainierte NLP-Modelle**\n",
    "Um die Textrepr√§sentation zu verbessern, verwenden wir:\n",
    "- **TF-IDF**: Konvertiert Texte in numerische Merkmale basierend auf Wortwichtigkeit.\n",
    "- **GloVe**: Vortrainierte Embeddings zur besseren Erfassung von Wortbeziehungen.\n",
    "- **Emoji2Vec**: Spezielle Embeddings zur Interpretation von Emojis.\n",
    "- **BERT**: Kontextuelle Embeddings f√ºr tiefere semantische Analysen.\n",
    "\n",
    "**Nach diesem Schritt ist das Notebook bereit f√ºr das Preprocessing und Feature Engineering.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotheken importieren\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Eigene Module importieren (Datenaufbereitung, Preprocessing, Modelltraining)\n",
    "from dataset_preparation import load_twitter_data, split_data\n",
    "from preprocess import (\n",
    "    preprocess_tweet,\n",
    "    vectorize_with_tfidf,\n",
    "    load_glove_embeddings,\n",
    "    vectorize_with_glove,\n",
    "    load_emoji2vec,\n",
    "    vectorize_with_emojis,\n",
    "    load_bert_model,\n",
    "    vectorize_with_bert,\n",
    ")\n",
    "from train_model import train_lightgbm, evaluate_model, plot_confusion_matrix\n",
    "\n",
    "# NLTK-Ressourcen f√ºr Textverarbeitung herunterladen (einmalig)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "\n",
    "# Best√§tigung, dass alle Ressourcen geladen wurden\n",
    "print(\"Alle NLP-Ressourcen und Bibliotheken erfolgreich importiert.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preprocessing: Bereinigung & Feature-Engineering\n",
    "\n",
    "Dieser Schritt bereitet die Rohdaten auf, indem Tweets bereinigt, tokenisiert und in numerische Features umgewandelt werden.  \n",
    "\n",
    "## **Schritte im Preprocessing**\n",
    "1. **Datenaufteilung (Train, Valid, Test)**  \n",
    "   - Sicherstellen, dass alle Sets gleichm√§√üig balanciert sind.\n",
    "\n",
    "2. **Textbereinigung & Tokenization**  \n",
    "   - Entfernen von **URLs, Mentions (@username), Sonderzeichen & Emojis**.  \n",
    "   - Tokenization: Zerlegen von S√§tzen in einzelne W√∂rter.\n",
    "\n",
    "3. **Linguistische Verarbeitung**  \n",
    "   - Entfernen von **Stopw√∂rtern** (h√§ufige, nicht informative W√∂rter wie \"the\", \"and\").  \n",
    "   - **Lemmatisierung**: Reduzieren von W√∂rtern auf ihre Grundform (z. B. \"running\" ‚Üí \"run\").\n",
    "\n",
    "4. **Feature-Vektorisierung**  \n",
    "   - **TF-IDF**: Repr√§sentiert W√∂rter basierend auf ihrer H√§ufigkeit & Relevanz.  \n",
    "   - **GloVe**: Vortrainierte Wort-Embeddings f√ºr semantische √Ñhnlichkeiten.  \n",
    "   - **Emoji2Vec**: Spezielle Embeddings f√ºr Emojis.  \n",
    "   - **BERT**: Kontextuelle Wort-Embeddings, die den Satzkontext ber√ºcksichtigen.\n",
    "\n",
    "**Nach diesem Schritt sind die Daten bereit f√ºr das Modelltraining.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten aufteilen\n",
    "from dataset_preparation import split_data\n",
    "\n",
    "# Datenaufteilung: Sicherstellen eines balancierten Datensatzes\n",
    "print(\"Teile Daten in Training, Validierung und Test auf...\")\n",
    "X_train, X_valid, X_test, y_train, y_valid, y_test = split_data(\n",
    "    positive_tweets, negative_tweets, balance=True\n",
    ")\n",
    "\n",
    "# √úbersicht √ºber die Datengr√∂√üen\n",
    "print(f\"Train Size: {len(X_train)}, Valid Size: {len(X_valid)}, Test Size: {len(X_test)}\")\n",
    "print(f\"Training: {sum(y_train)} positive, {len(y_train) - sum(y_train)} negative\")\n",
    "print(f\"Validation: {sum(y_valid)} positive, {len(y_valid) - sum(y_valid)} negative\")\n",
    "print(f\"Test: {sum(y_test)} positive, {len(y_test) - sum(y_test)} negative\")\n",
    "\n",
    "\n",
    "# Vorverarbeitung der Tweets mit NLP-Techniken\n",
    "print(\"Starte Preprocessing (Tokenization, Stemming, Bereinigung)...\")\n",
    "X_train_preprocessed = [preprocess_tweet(tweet) for tweet in X_train]\n",
    "X_valid_preprocessed = [preprocess_tweet(tweet) for tweet in X_valid]\n",
    "X_test_preprocessed = [preprocess_tweet(tweet) for tweet in X_test]\n",
    "print(\"Preprocessing abgeschlossen.\")\n",
    "\n",
    "# Beispielhafte Ausgabe f√ºr ein besseres Verst√§ndnis\n",
    "print(\"\\nBeispiel-Tweet vor und nach Preprocessing:\")\n",
    "print(f\"Original: {X_train[0]}\")\n",
    "print(f\"Preprocessed: {X_train_preprocessed[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Datenaufteilung\n",
    "\n",
    "In diesem Schritt werden die geladenen Tweets in **Trainings-, Validierungs- und Testdatens√§tze** aufgeteilt.\n",
    "\n",
    "## **Ziel der Datenaufteilung**\n",
    "- **Training**: Hauptdatensatz f√ºr das Modelltraining.  \n",
    "- **Validierung**: Wird genutzt, um Hyperparameter anzupassen und Overfitting zu vermeiden.  \n",
    "- **Test**: Unabh√§ngige Bewertung des finalen Modells.\n",
    "\n",
    "## **Stratifizierte Aufteilung**\n",
    "- Sicherstellt, dass die **Klassenverteilung in allen Sets konsistent bleibt**.\n",
    "- Verhindert, dass eine Klasse (positive/negative Tweets) dominiert.\n",
    "\n",
    "## **Balance der Daten**\n",
    "- Falls eine Klasse dominiert, wird **Oversampling** angewendet, um ein **ausgewogenes Verh√§ltnis** zu garantieren.  \n",
    "- Dies verhindert, dass das Modell eine **Klassenverzerrung** lernt.\n",
    "\n",
    "Nach diesem Schritt haben wir ein **gleichm√§√üig verteiltes Dataset**, bereit f√ºr die Feature-Vektorisierung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notwendige Funktionen f√ºr die Datenaufteilung importieren\n",
    "from dataset_preparation import load_twitter_data, split_data\n",
    "\n",
    "# Tweets laden\n",
    "positive_tweets, negative_tweets = load_twitter_data()\n",
    "\n",
    "# Aufteilung in Trainings-, Validierungs- und Testdatens√§tze\n",
    "print(\"Teile Daten in Training, Validierung und Test auf...\")\n",
    "X_train, X_valid, X_test, y_train, y_valid, y_test = split_data(\n",
    "    positive_tweets, negative_tweets, balance=True\n",
    ")\n",
    "\n",
    "# 4. √úberblick √ºber die Datengr√∂√üe & Klassendistribution\n",
    "print(f\"Trainingsset: {len(X_train)} Samples\")\n",
    "print(f\"Validierungsset: {len(X_valid)} Samples\")\n",
    "print(f\"Testset: {len(X_test)} Samples\")\n",
    "\n",
    "print(\"\\nKlassenverteilung pro Datensatz:\")\n",
    "print(f\"Training: {sum(y_train)} positive, {len(y_train) - sum(y_train)} negative\")\n",
    "print(f\"Validation: {sum(y_valid)} positive, {len(y_valid) - sum(y_valid)} negative\")\n",
    "print(f\"Test: {sum(y_test)} positive, {len(y_test) - sum(y_test)} negative\")\n",
    "\n",
    "# 5. Beispiel-Tweet aus den Trainingsdaten ausgeben\n",
    "print(\"\\nBeispiel-Tweet aus dem Trainingsdatensatz:\")\n",
    "print(f\"Tweet: {X_train[0]}\")\n",
    "print(f\"Label: {'Positiv' if y_train[0] == 1 else 'Negativ'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Feature-Engineering: Text in Vektoren umwandeln\n",
    "\n",
    "Um Tweets in ein numerisches Format f√ºr das Modelltraining zu √ºberf√ºhren, verwenden wir verschiedene Vektorisierungsmethoden.  \n",
    "\n",
    "## **Warum verschiedene Methoden kombinieren?**\n",
    "Jede Methode hat eigene Vorteile:\n",
    "- **TF-IDF**: H√§ufigkeitsbasierte Repr√§sentation, die wichtige W√∂rter hervorhebt.\n",
    "- **GloVe**: Semantische Wortbeziehungen durch vortrainierte Embeddings.\n",
    "- **Emoji2Vec**: Ber√ºcksichtigt die Bedeutung von Emojis im Sentiment.\n",
    "- **BERT**: Kontextuelle Wort-Embeddings f√ºr tiefere semantische Analysen.\n",
    "\n",
    "Durch die Kombination dieser Methoden erh√§lt das Modell eine **reichhaltige Repr√§sentation der Tweets**.\n",
    "\n",
    "---\n",
    "\n",
    "## **√úbersicht der Methoden**\n",
    "| Methode      | Beschreibung |\n",
    "|-------------|-------------|\n",
    "| **TF-IDF**  | Repr√§sentiert W√∂rter basierend auf ihrer H√§ufigkeit & Bedeutung im Text. |\n",
    "| **GloVe**   | Vortrainierte Wort-Embeddings f√ºr bessere semantische Erkennung. |\n",
    "| **Emoji2Vec** | Spezielle Embeddings zur Erkennung von Emoji-Bedeutungen. |\n",
    "| **BERT**   | Kontextuelle Embeddings, die den Wortkontext erfassen. |\n",
    "\n",
    "- **Nach diesem Schritt sind die Tweets in numerischer Form und bereit f√ºr das Modelltraining!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Importieren der Vektorisierungsfunktionen\n",
    "from preprocess import (\n",
    "    vectorize_with_tfidf,\n",
    "    load_glove_embeddings,\n",
    "    vectorize_with_glove,\n",
    "    load_emoji2vec,\n",
    "    vectorize_with_emojis,\n",
    "    load_bert_model,\n",
    "    vectorize_with_bert,\n",
    ")\n",
    "\n",
    "# Sicherstellen, dass das Arbeitsverzeichnis korrekt gesetzt ist\n",
    "current_dir = os.getcwd()\n",
    "project_dir = os.path.abspath(os.path.join(current_dir, \"./\"))\n",
    "\n",
    "if current_dir != project_dir:\n",
    "    os.chdir(project_dir)\n",
    "\n",
    "# Definiere Pfade zu den vortrainierten Embeddings\n",
    "glove_path = \"../data/glove.twitter.27B.200d.txt\"\n",
    "emoji2vec_path = \"../data/emoji2vec.txt\"\n",
    "\n",
    "# Laden der vortrainierten Embeddings\n",
    "\n",
    "# GloVe-Embeddings laden\n",
    "print(\"Lade GloVe-Embeddings...\")\n",
    "glove_embeddings, glove_mean = load_glove_embeddings(glove_path)\n",
    "\n",
    "# Emoji2Vec-Embeddings laden\n",
    "print(\"Lade Emoji2Vec-Embeddings...\")\n",
    "emoji_vectors = load_emoji2vec(emoji2vec_path)\n",
    "\n",
    "# BERT-Modell laden\n",
    "print(\"Lade BERT-Modell...\")\n",
    "tokenizer, bert_model = load_bert_model(\"distilbert-base-uncased\")\n",
    "\n",
    "# Feature-Vektorisierung der Tweets\n",
    "\n",
    "# TF-IDF-Vektorisierung\n",
    "print(\"Vektorisieren mit TF-IDF...\")\n",
    "tfidf_matrix_train, tfidf_vectorizer = vectorize_with_tfidf(X_train_preprocessed)\n",
    "tfidf_matrix_valid = tfidf_vectorizer.transform(X_valid_preprocessed)\n",
    "tfidf_matrix_test = tfidf_vectorizer.transform(X_test_preprocessed)\n",
    "\n",
    "# GloVe-Vektorisierung\n",
    "print(\"Vektorisieren mit GloVe...\")\n",
    "glove_matrix_train = vectorize_with_glove(X_train_preprocessed, glove_embeddings, glove_mean)\n",
    "glove_matrix_valid = vectorize_with_glove(X_valid_preprocessed, glove_embeddings, glove_mean)\n",
    "glove_matrix_test = vectorize_with_glove(X_test_preprocessed, glove_embeddings, glove_mean)\n",
    "\n",
    "# Emoji2Vec-Vektorisierung\n",
    "print(\"Vektorisieren mit Emoji2Vec...\")\n",
    "emoji_matrix_train = vectorize_with_emojis(X_train_preprocessed, emoji_vectors)\n",
    "emoji_matrix_valid = vectorize_with_emojis(X_valid_preprocessed, emoji_vectors)\n",
    "emoji_matrix_test = vectorize_with_emojis(X_test_preprocessed, emoji_vectors)\n",
    "\n",
    "# BERT-Vektorisierung\n",
    "print(\"Vektorisieren mit BERT...\")\n",
    "bert_matrix_train = vectorize_with_bert(X_train, tokenizer, bert_model)\n",
    "bert_matrix_valid = vectorize_with_bert(X_valid, tokenizer, bert_model)\n",
    "bert_matrix_test = vectorize_with_bert(X_test, tokenizer, bert_model)\n",
    "\n",
    "print(\"Feature-Engineering abgeschlossen! Alle Tweets wurden in numerische Form √ºberf√ºhrt.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Modelltraining mit LightGBM\n",
    "\n",
    "In diesem Schritt trainieren wir ein **LightGBM-Modell**, das f√ºr tabellarische Daten besonders gut geeignet ist.  \n",
    "\n",
    "## **Warum LightGBM?**\n",
    "- Besonders effizient f√ºr gro√üe tabellarische Daten.  \n",
    "- Unterst√ºtzt automatische Gewichtung unausgeglichener Klassen.  \n",
    "- Bietet hohe Trainingsgeschwindigkeit & gute Generalisierung.  \n",
    "\n",
    "---\n",
    "\n",
    "## **Modell-Einstellungen**\n",
    "| **Hyperparameter** | **Beschreibung** |\n",
    "|--------------------|-----------------|\n",
    "| `n_estimators=500` | Anzahl der Entscheidungsb√§ume |\n",
    "| `max_depth=20` | Maximale Tiefe der B√§ume |\n",
    "| `class_weight=\"balanced\"` | Automatischer Ausgleich der Klassen |\n",
    "\n",
    "---\n",
    "\n",
    "## **Ablauf des Modelltrainings**\n",
    "1. **Feature-Kombination**  \n",
    "   - TF-IDF, GloVe, Emoji2Vec und BERT-Features werden zu einem einzigen Feature-Set kombiniert.\n",
    "2. **Feature-Skalierung**  \n",
    "   - Standardisiert die Daten, um Verzerrungen zu vermeiden.\n",
    "3. **Training des LightGBM-Modells**  \n",
    "   - Modell wird mit den optimierten Features trainiert.\n",
    "4. **Modellbewertung**  \n",
    "   - **Testgenauigkeit**, **Confusion Matrix** und **Classification Report** werden analysiert.\n",
    "\n",
    "**Nach diesem Schritt haben wir ein trainiertes Modell, das Tweets nach ihrem Sentiment klassifizieren kann.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from train_model import train_lightgbm, evaluate_model, plot_confusion_matrix\n",
    "\n",
    "# Feature-Kombination: Zusammenf√ºhren aller numerischen Darstellungen\n",
    "print(\"Kombiniere Features aus verschiedenen Vektorisierungen...\")\n",
    "combined_train = np.hstack([tfidf_matrix_train.toarray(), glove_matrix_train, emoji_matrix_train, bert_matrix_train])\n",
    "combined_valid = np.hstack([tfidf_matrix_valid.toarray(), glove_matrix_valid, emoji_matrix_valid, bert_matrix_valid])\n",
    "combined_test = np.hstack([tfidf_matrix_test.toarray(), glove_matrix_test, emoji_matrix_test, bert_matrix_test])\n",
    "\n",
    "# Skalierung der Features f√ºr gleichm√§√üige Verteilung\n",
    "print(\"Skaliere Features f√ºr optimales Modellverhalten...\")\n",
    "scaler = StandardScaler()\n",
    "combined_train_scaled = scaler.fit_transform(combined_train)\n",
    "combined_valid_scaled = scaler.transform(combined_valid)\n",
    "combined_test_scaled = scaler.transform(combined_test)\n",
    "\n",
    "# Modelltraining mit LightGBM\n",
    "print(\"Trainiere LightGBM-Modell...\")\n",
    "model = train_lightgbm(combined_train_scaled, y_train)\n",
    "\n",
    "# Bewertung des trainierten Modells\n",
    "print(\"Bewerte das Modell auf den Testdaten...\")\n",
    "accuracy, conf_matrix, report = evaluate_model(model, combined_test_scaled, y_test)\n",
    "\n",
    "# Ergebnisse anzeigen\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Classification Report:\\n\", report)\n",
    "# Visualisierung der Confusion Matrix\n",
    "print(\"\\n Erstelle Confusion Matrix...\")\n",
    "plot_confusion_matrix(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Modellbewertung\n",
    "\n",
    "Nach dem Training wird das Modell mit den **Testdaten** bewertet, um die endg√ºltige Leistung zu messen.  \n",
    "\n",
    "## **Bewertungsmethoden**\n",
    "### **Testgenauigkeit (Accuracy)**\n",
    "- Zeigt an, wie viele Vorhersagen insgesamt korrekt sind.\n",
    "\n",
    "### **Classification Report**\n",
    "- **Precision**: Anteil der korrekten positiven Vorhersagen an allen positiven Vorhersagen.  \n",
    "- **Recall**: Anteil der korrekt erkannten positiven Tweets an allen tats√§chlichen positiven Tweets.  \n",
    "- **F1-Score**: Harmonisches Mittel aus Precision & Recall ‚Äì optimale Balance zwischen beiden Metriken.  \n",
    "\n",
    "### **Confusion Matrix**\n",
    "- Zeigt die Klassifikationsleistung durch:\n",
    "  - **True Positives (TP)**: Korrekt als positiv klassifiziert.\n",
    "  - **True Negatives (TN)**: Korrekt als negativ klassifiziert.\n",
    "  - **False Positives (FP)**: Falsch als positiv klassifiziert (Fehlalarme).\n",
    "  - **False Negatives (FN)**: Falsch als negativ klassifiziert (√ºbersehene positive Tweets).\n",
    "\n",
    "## **Zielsetzung**\n",
    "**Genauigkeit von mindestens 90 %** erreichen.  \n",
    "**Analyse der Fehlklassifikationen** f√ºr potenzielle Verbesserungen.  \n",
    "**Interpretation der Confusion Matrix**, um herauszufinden, wo das Modell Fehler macht.\n",
    "\n",
    "**Nach diesem Schritt wissen wir, ob unser Modell zuverl√§ssig ist oder verbessert werden muss.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testgenauigkeit ausgeben\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "# Classification Report anzeigen\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Confusion Matrix visualisieren\n",
    "plot_confusion_matrix(conf_matrix)\n",
    "\n",
    "# Fehleranalyse ‚Äì Anzahl der Fehlklassifikationen\n",
    "false_positives = (conf_matrix[0][1]) # Falsch-positive Vorhersagen (FP)\n",
    "false_negatives = (conf_matrix[1][0]) # Falsch-negative Vorhersagen (FN)\n",
    "\n",
    "# üîç Zus√§tzliche Fehlklassifikationsanalyse\n",
    "print(\"\\n**Fehlklassifikationen:**\")\n",
    "print(f\"False Positives (FP): {false_positives} ‚Äì Negative Tweets f√§lschlicherweise als positiv erkannt.\")\n",
    "print(f\"False Negatives (FN): {false_negatives} ‚Äì Positive Tweets nicht erkannt.\")\n",
    "\n",
    "# üîπ 5. Interpretation der Ergebnisse\n",
    "if accuracy >= 0.90:\n",
    "    print(\"\\n**Das Modell hat eine hervorragende Genauigkeit von √ºber 90%!**\")\n",
    "else:\n",
    "    print(\"\\n**Die Genauigkeit liegt unter 90%. √úberpr√ºfung der Feature-Auswahl & Hyperparameter n√∂tig!**\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Fazit: Sentiment-Analyse mit NLP\n",
    "\n",
    "Dieses Projekt hat moderne NLP-Techniken kombiniert, um ein **robustes Modell f√ºr die Sentiment-Analyse von Tweets** zu entwickeln.  \n",
    "Mit einer erreichten Genauigkeit von **96.40 %** √ºbertrifft das Modell die urspr√ºngliche Zielsetzung von **90 %** deutlich.\n",
    "\n",
    "---\n",
    "\n",
    "## **Ergebnisse & Modellbewertung**\n",
    "| Metrik          | Ergebnis |\n",
    "|----------------|---------|\n",
    "| **Test-Genauigkeit**  | **96.40 %**|\n",
    "| **Precision (Positiv/Negativ)**  | Sehr ausgeglichen|\n",
    "| **Recall (Positiv/Negativ)**  | Hohe Erkennungsrate|\n",
    "| **F1-Score** | Zeigt robuste Modellleistung|\n",
    "\n",
    "**Warum ist das Modell stark?**\n",
    "- **Gute Balance zwischen Precision & Recall** ‚Üí Keine √úbergewichtung einer Klasse.  \n",
    "- **Kombination mehrerer Features verbessert die Generalisierbarkeit.**  \n",
    "- **LightGBM ist effizient & skalierbar f√ºr gro√üe Textdaten.**  \n",
    "\n",
    "---\n",
    "\n",
    "## **Verwendete Technologien**\n",
    "Das Modell nutzt eine Kombination aus **bew√§hrten NLP-Techniken** und **fortschrittlichen Embeddings**:\n",
    "- **TF-IDF**: Stellt Text numerisch dar und hebt wichtige Begriffe hervor.\n",
    "- **GloVe & Emoji2Vec**: Erg√§nzen sich durch **semantische und emoji-spezifische Features**.\n",
    "- **BERT**: Liefert **kontextuelle Embeddings**, die die Modellleistung erheblich verbessern.\n",
    "- **LightGBM**: Sehr effizientes Modell f√ºr tabellarische Daten, das schnell trainiert werden kann.\n",
    "\n",
    "---\n",
    "\n",
    "## **Herausforderungen**\n",
    "**Feature-Kombination & Modellkomplexit√§t**  \n",
    "   - Das Zusammenf√ºhren verschiedener Embeddings (TF-IDF, GloVe, BERT) erh√∂ht die **Modellkomplexit√§t** und kann zu Overfitting f√ºhren.  \n",
    "**Hoher Speicherbedarf**  \n",
    "   - **BERT ist speicherintensiv**, besonders bei gr√∂√üeren Datens√§tzen.  \n",
    "**Datenaufbereitung ist zeitaufwendig**  \n",
    "   - **Bereinigung & Preprocessing** (z. B. Tokenization, Stemming) erfordern viel Rechenleistung.  \n",
    "\n",
    "---\n",
    "\n",
    "## **M√∂gliche Verbesserungen**\n",
    "**1. Hyperparameter-Tuning**  \n",
    "   - Optimierung von `learning_rate`, `max_depth`, `n_estimators` f√ºr **bessere Modellleistung**.  \n",
    "   - Einsatz von **GridSearchCV oder Optuna** zur automatischen Optimierung.  \n",
    "\n",
    "**2. Datenaugmentation f√ºr robustere Modelle**  \n",
    "   - **Synonym-Ersetzung** (WordNet) ‚Üí Vergr√∂√üerung des Trainingssets.  \n",
    "   - **Back-Translation** ‚Üí Tweets automatisch in eine andere Sprache √ºbersetzen & zur√ºck√ºbersetzen.  \n",
    "   - **Random Noise & Dropout auf TF-IDF Features** zur Generalisierung.  \n",
    "\n",
    "**3. Alternative Modellarchitekturen testen**  \n",
    "   - **XGBoost oder CatBoost** als alternative Ensemble-Methoden f√ºr mehr Robustheit.  \n",
    "   - **Transformer-basierte Modelle (RoBERTa, GPT-3)** f√ºr tiefere Textverst√§ndnisanalysen.  \n",
    "   - **Multimodale NLP-Modelle** ‚Üí Kombination von Text- & Bilddaten f√ºr bessere Kontextverarbeitung.  \n",
    "\n",
    "---\n",
    "\n",
    "## **Zusammenfassung & Fazit**\n",
    "**Was wurde erreicht?**\n",
    "- Eine **hocheffiziente Sentiment-Analyse mit NLP-Techniken** entwickelt.  \n",
    "- **Kombination aus TF-IDF, GloVe, Emoji2Vec und BERT** erm√∂glicht starke Modellperformance.  \n",
    "- **LightGBM erwies sich als robustes Modell**, das schnelle Trainingszeiten mit hoher Genauigkeit kombiniert.\n",
    "\n",
    "**N√§chste Schritte**  \n",
    "- **Feinabstimmung der Hyperparameter**, um das Potenzial des Modells weiter auszusch√∂pfen.  \n",
    "- **Erweiterung der Daten durch Augmentation**, um Generalisierung zu verbessern.  \n",
    "- **Test von transformerbasierten Deep-Learning-Modellen (z. B. RoBERTa, T5)**.\n",
    "\n",
    "**Fazit:** Dieses Projekt zeigt, dass durch **moderne NLP-Techniken und Ensemble-Lernmethoden** eine **hohe Genauigkeit in der Sentiment-Analyse** erreicht werden kann."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
